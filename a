how to create curl for app.post("/process-image/")


"# Import necessary libraries
import nest_asyncio
import uvicorn
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import StreamingResponse, JSONResponse
from pyngrok import ngrok
import cv2
import numpy as np
from io import BytesIO
from PIL import Image
import asyncio
from ultralytics import YOLO
import base64

# Apply nest_asyncio to allow running FastAPI in Jupyter
nest_asyncio.apply()

# Initialize FastAPI app
app = FastAPI()

# Load YOLOv11 model (choose appropriate model variant: yolov11n, yolov11s, etc.)


# Load a model
model = YOLO("yolo11n.pt")


# Health check endpoint
@app.get("/health")
async def health_check():
    return JSONResponse(content={"status": "healthy"}, status_code=200)

# Define the image processing function with YOLOv11
def process_image(image: np.ndarray, prompt: str) -> tuple:
    # Perform YOLOv11 inference
    results = model(image)

    # Extract detection results
    detections = results[0].boxes  # Get bounding boxes
    bounding_boxes = detections.xyxy.cpu().numpy().tolist()  # [x1, y1, x2, y2]
    confidences = detections.conf.cpu().numpy().tolist()  # Confidence scores
    class_ids = detections.cls.cpu().numpy().astype(int).tolist()  # Class IDs

    # Get class names
    class_names = [model.names[cls_id] for cls_id in class_ids]

    # Draw bounding boxes on the image
    processed_image = image.copy()
    for box, conf, cls_name in zip(bounding_boxes, confidences, class_names):
        x1, y1, x2, y2 = map(int, box)
        # Draw rectangle
        cv2.rectangle(processed_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        # Add label
        label = f"{cls_name} {conf:.2f}"
        cv2.putText(processed_image, label, (x1, y1 - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return processed_image, bounding_boxes, class_names, confidences

# FastAPI endpoint to handle image upload and prompt
@app.post("/process-image/")
async def process_image_endpoint(file: UploadFile = File(...), prompt: str = Form(...)):
    try:
        # Read the uploaded image
        image_data = await file.read()
        image = Image.open(BytesIO(image_data)).convert("RGB")
        image_np = np.array(image)

        # Process the image with YOLOv11
        processed_image_np, bounding_boxes, class_names, confidences = process_image(image_np, prompt)

        # Convert processed image to base64 for JSON response
        processed_image_pil = Image.fromarray(processed_image_np)
        buffer = BytesIO()
        processed_image_pil.save(buffer, format="PNG")
        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

        print("Image processed successfully.")
        

        # Prepare response data
        response_data = {
            "processed_image": f"data:image/png;base64,{img_base64}",
            "bounding_boxes": bounding_boxes,  # [[x1, y1, x2, y2], ...]
            "classes": class_names,           # ["class_name1", "class_name2", ...]
            "confidences": confidences,       # [conf1, conf2, ...]
            "message": "Image processed successfully"
        }

        return JSONResponse(content=response_data, status_code=200)

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)
"